{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68bc4d7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading https://www.chrsmrrs.com/graphkerneldatasets/MUTAG.zip\n",
      "Processing...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import TUDataset\n",
    "\n",
    "# Specify a root directory for storing data (adjust path as needed)\n",
    "MUTAG = TUDataset(root='data/TUDataset', name='MUTAG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7985bbb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of graphs: 188\n",
      "Number of node features: 7\n",
      "Number of edge features: 4\n",
      "Number of classes: 2\n"
     ]
    }
   ],
   "source": [
    "# Print summary statistics\n",
    "print(f\"Number of graphs: {len(MUTAG)}\")\n",
    "print(f\"Number of node features: {MUTAG.num_node_features}\")\n",
    "print(f\"Number of edge features: {MUTAG.num_edge_features}\")\n",
    "print(f\"Number of classes: {MUTAG.num_classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eaaf70d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def build_graph_features(dataset):\n",
    "    # detect if continuous features exist\n",
    "    has_continuous = any(getattr(d, 'x', None) is not None for d in dataset)\n",
    "    # detect discrete node labels\n",
    "    has_node_label = any(getattr(d, 'node_label', None) is not None for d in dataset)\n",
    "    global_label_count = None\n",
    "\n",
    "    if not has_continuous and has_node_label:\n",
    "        # find maximum label to create consistent histogram length\n",
    "        max_lbl = 0\n",
    "        for d in dataset:\n",
    "            nl = getattr(d, 'node_label', None)\n",
    "            if nl is not None and nl.numel() > 0:\n",
    "                max_lbl = max(max_lbl, int(nl.max().item()))\n",
    "        global_label_count = max_lbl + 1\n",
    "\n",
    "    X_list = []\n",
    "    y_list = []\n",
    "    for d in dataset:\n",
    "        feats = []\n",
    "        n_nodes = d.num_nodes\n",
    "        n_edges = d.num_edges\n",
    "        avg_deg = (2.0 * n_edges / n_nodes) if n_nodes > 0 else 0.0\n",
    "        feats.extend([n_nodes, n_edges, avg_deg])\n",
    "\n",
    "        if getattr(d, 'x', None) is not None:\n",
    "            x = d.x.cpu().numpy()  # shape (n_nodes, num_node_features)\n",
    "            # summary statistics for each node feature\n",
    "            means = x.mean(axis=0)\n",
    "            stds  = x.std(axis=0)\n",
    "            sums  = x.sum(axis=0)\n",
    "            mins  = x.min(axis=0)\n",
    "            maxs  = x.max(axis=0)\n",
    "            feats.extend(means.tolist())\n",
    "            feats.extend(stds.tolist())\n",
    "            feats.extend(sums.tolist())\n",
    "            feats.extend(mins.tolist())\n",
    "            feats.extend(maxs.tolist())\n",
    "        elif getattr(d, 'node_label', None) is not None:\n",
    "            nl = d.node_label.cpu().numpy().astype(int)\n",
    "            L = global_label_count or (int(nl.max()) + 1 if nl.size>0 else 1)\n",
    "            hist = np.zeros(L, dtype=float)\n",
    "            for lbl in nl:\n",
    "                if 0 <= int(lbl) < L:\n",
    "                    hist[int(lbl)] += 1.0\n",
    "            # normalize histogram\n",
    "            hist = hist / (hist.sum() + 1e-12)\n",
    "            feats.extend(hist.tolist())\n",
    "        else:\n",
    "            # no node-level info: nothing extra\n",
    "            pass\n",
    "\n",
    "        X_list.append(np.array(feats, dtype=float))\n",
    "        # graph-level label y\n",
    "        label = d.y\n",
    "        if isinstance(label, torch.Tensor):\n",
    "            label = int(label.item()) if label.numel() == 1 else label.cpu().numpy()\n",
    "        y_list.append(int(label))\n",
    "\n",
    "    # ensure consistent feature length by padding if needed\n",
    "    lengths = [len(x) for x in X_list]\n",
    "    if len(set(lengths)) != 1:\n",
    "        max_len = max(lengths)\n",
    "        X_padded = np.zeros((len(X_list), max_len), dtype=float)\n",
    "        for i, x in enumerate(X_list):\n",
    "            X_padded[i, :len(x)] = x\n",
    "        X = X_padded\n",
    "    else:\n",
    "        X = np.vstack(X_list)\n",
    "    y = np.array(y_list, dtype=int)\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16ef0023",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = build_graph_features(MUTAG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c6bc76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from grakel.kernels import WeisfeilerLehman, VertexHistogram\n",
    "\n",
    "wl_kernel = WeisfeilerLehman(n_iter=5, normalize=True, base_graph_kernel=VertexHistogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "048392ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ecfb18d3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unsupported input type. For more information check the documentation, concerning valid input types for graph type object.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m K_train = \u001b[43mwl_kernel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m K_test = wl_kernel.transform(X_test)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\alams\\anaconda3\\envs\\qml\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:316\u001b[39m, in \u001b[36m_wrap_method_output.<locals>.wrapped\u001b[39m\u001b[34m(self, X, *args, **kwargs)\u001b[39m\n\u001b[32m    314\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[32m    315\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m316\u001b[39m     data_to_wrap = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    317\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    318\u001b[39m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[32m    319\u001b[39m         return_tuple = (\n\u001b[32m    320\u001b[39m             _wrap_data_with_container(method, data_to_wrap[\u001b[32m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[32m    321\u001b[39m             *data_to_wrap[\u001b[32m1\u001b[39m:],\n\u001b[32m    322\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\alams\\anaconda3\\envs\\qml\\Lib\\site-packages\\grakel\\kernels\\weisfeiler_lehman.py:298\u001b[39m, in \u001b[36mWeisfeilerLehman.fit_transform\u001b[39m\u001b[34m(self, X, y)\u001b[39m\n\u001b[32m    296\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m'\u001b[39m\u001b[33mtransform input cannot be None\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    297\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m298\u001b[39m     km, \u001b[38;5;28mself\u001b[39m.X = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparse_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    300\u001b[39m \u001b[38;5;28mself\u001b[39m._X_diag = np.diagonal(km)\n\u001b[32m    301\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.normalize:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\alams\\anaconda3\\envs\\qml\\Lib\\site-packages\\grakel\\kernels\\weisfeiler_lehman.py:158\u001b[39m, in \u001b[36mWeisfeilerLehman.parse_input\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    156\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(x) > \u001b[32m3\u001b[39m:\n\u001b[32m    157\u001b[39m         extra = \u001b[38;5;28mtuple\u001b[39m(x[\u001b[32m3\u001b[39m:])\n\u001b[32m--> \u001b[39m\u001b[32m158\u001b[39m     x = \u001b[43mGraph\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgraph_format\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_graph_format\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    159\u001b[39m     extra = (x.get_labels(purpose=\u001b[38;5;28mself\u001b[39m._graph_format,\n\u001b[32m    160\u001b[39m                           label_type=\u001b[33m\"\u001b[39m\u001b[33medge\u001b[39m\u001b[33m\"\u001b[39m, return_none=\u001b[38;5;28;01mTrue\u001b[39;00m), ) + extra\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\alams\\anaconda3\\envs\\qml\\Lib\\site-packages\\grakel\\graph.py:162\u001b[39m, in \u001b[36mGraph.__init__\u001b[39m\u001b[34m(self, initialization_object, node_labels, edge_labels, graph_format, construct_labels)\u001b[39m\n\u001b[32m    160\u001b[39m \u001b[38;5;28mself\u001b[39m._format = graph_format\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (initialization_object \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m162\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbuild_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43minitialization_object\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m                     \u001b[49m\u001b[43mnode_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m                     \u001b[49m\u001b[43medge_labels\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m graph_format == \u001b[33m\"\u001b[39m\u001b[33mauto\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    166\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m'\u001b[39m\u001b[33mno initialization object \u001b[39m\u001b[33m'\u001b[39m +\n\u001b[32m    167\u001b[39m                      \u001b[33m'\u001b[39m\u001b[33m- format must not be auto\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\alams\\anaconda3\\envs\\qml\\Lib\\site-packages\\grakel\\graph.py:219\u001b[39m, in \u001b[36mGraph.build_graph\u001b[39m\u001b[34m(self, g, node_labels, edge_labels)\u001b[39m\n\u001b[32m    217\u001b[39m             \u001b[38;5;28mself\u001b[39m._format = \u001b[33m\"\u001b[39m\u001b[33mdictionary\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    218\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m219\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    220\u001b[39m             \u001b[33m'\u001b[39m\u001b[33mUnsupported input type. For more information \u001b[39m\u001b[33m'\u001b[39m +\n\u001b[32m    221\u001b[39m             \u001b[33m'\u001b[39m\u001b[33mcheck the documentation, concerning valid input \u001b[39m\u001b[33m'\u001b[39m +\n\u001b[32m    222\u001b[39m             \u001b[33m'\u001b[39m\u001b[33mtypes for graph type object.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    224\u001b[39m \u001b[38;5;66;03m# If graph is of one type prune the other\u001b[39;00m\n\u001b[32m    225\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._format == \u001b[33m\"\u001b[39m\u001b[33madjacency\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[31mValueError\u001b[39m: Unsupported input type. For more information check the documentation, concerning valid input types for graph type object."
     ]
    }
   ],
   "source": [
    "K_train = wl_kernel.fit_transform(X_train)\n",
    "K_test = wl_kernel.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29e07079",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
